{"step": 0}
{"episode_reward": 0.0, "episode": 1.0, "duration": 116.39235973358154, "info_performance_mean": 0.09032800048589706, "info_performance_final": 0.09273932874202728, "info_normalized_performance_mean": 0.15401770174503326, "info_normalized_performance_final": 0.16937901079654694, "step": 100}
{"episode_reward": 451.64003875854826, "episode": 2.0, "duration": 4.997730016708374, "info_performance_mean": 0.10028698295354843, "info_performance_final": 0.09952659904956818, "info_normalized_performance_mean": 0.2174612432718277, "info_normalized_performance_final": 0.21261729300022125, "step": 200}
{"episode_reward": 501.43488391452996, "episode": 3.0, "duration": 5.014570713043213, "info_performance_mean": 0.08905435353517532, "info_performance_final": 0.09254250675439835, "info_normalized_performance_mean": 0.14590394496917725, "info_normalized_performance_final": 0.168125182390213, "step": 300}
{"episode_reward": 445.2717953146571, "episode": 4.0, "duration": 5.053609609603882, "info_performance_mean": 0.07781608402729034, "info_performance_final": 0.07536080479621887, "info_normalized_performance_mean": 0.07431057095527649, "info_normalized_performance_final": 0.058669254183769226, "step": 400}
{"episode_reward": 389.0804032323178, "episode": 5.0, "duration": 5.106719017028809, "info_performance_mean": 0.06839881092309952, "info_performance_final": 0.06300917267799377, "info_normalized_performance_mean": 0.014317929744720459, "info_normalized_performance_final": -0.020016726106405258, "step": 500}
{"episode_reward": 341.9940624977243, "episode": 6.0, "duration": 5.029294490814209, "info_performance_mean": 0.08807874470949173, "info_performance_final": 0.1133338138461113, "info_normalized_performance_mean": 0.13968880474567413, "info_normalized_performance_final": 0.3005760610103607, "step": 600}
{"episode_reward": 440.3937279461702, "episode": 7.0, "duration": 5.131711006164551, "info_performance_mean": 0.06615610420703888, "info_performance_final": 0.0661449283361435, "info_normalized_performance_mean": 3.07653026538901e-05, "info_normalized_performance_final": -4.043071749038063e-05, "step": 700}
{"episode_reward": 330.7805158434485, "episode": 8.0, "duration": 5.015057563781738, "info_performance_mean": 0.07829168438911438, "info_performance_final": 0.07907340675592422, "info_normalized_performance_mean": 0.07734040170907974, "info_normalized_performance_final": 0.08232033252716064, "step": 800}
{"episode_reward": 391.45842813104315, "episode": 9.0, "duration": 5.112609148025513, "info_performance_mean": 0.08947835862636566, "info_performance_final": 0.11064133048057556, "info_normalized_performance_mean": 0.14860503375530243, "info_normalized_performance_final": 0.2834235727787018, "step": 900}
{"episode_reward": 447.391801390296, "episode": 10.0, "duration": 5.0046892166137695, "info_performance_mean": 0.0698695108294487, "info_performance_final": 0.08272229135036469, "info_normalized_performance_mean": 0.023687036707997322, "info_normalized_performance_final": 0.10556556284427643, "step": 1000}
{"episode_reward": 349.34757989874856, "episode": 11.0, "batch_reward": 4.115341923236847, "critic_loss": 0.7621536126732826, "critic_lr": 0.00030000000000000073, "actor_loss": -5.786086387634278, "actor_target_entropy": -8.0, "actor_entropy": 9.231781183481216, "actor_lr": 0.0003, "alpha_loss": 1.2134918788075446, "alpha_value": 0.09978985253636125, "duration": 76.40284943580627, "info_performance_mean": 0.09300604462623596, "info_performance_final": 0.09838604182004929, "info_normalized_performance_mean": 0.1710781455039978, "info_normalized_performance_final": 0.2053513526916504, "step": 1100}
{"episode_reward": 465.0302323328818, "episode": 12.0, "batch_reward": 4.115591914653778, "critic_loss": 0.07736910002306104, "critic_lr": 0.00030000000000000073, "actor_loss": -7.570246067047119, "actor_target_entropy": -8.0, "actor_entropy": 10.30245750427246, "actor_lr": 0.0003, "alpha_loss": 1.3180372405052185, "alpha_value": 0.09928195352602932, "duration": 77.20718574523926, "info_performance_mean": 0.06795607507228851, "info_performance_final": 0.07384732365608215, "info_normalized_performance_mean": 0.011497489176690578, "info_normalized_performance_final": 0.049027640372514725, "step": 1200}
{"episode_reward": 339.7803879791684, "episode": 13.0, "batch_reward": 4.106262702941894, "critic_loss": 0.11883447907865047, "critic_lr": 0.00030000000000000073, "actor_loss": -9.178531723022461, "actor_target_entropy": -8.0, "actor_entropy": 10.325970554351807, "actor_lr": 0.0003, "alpha_loss": 1.3197169589996338, "alpha_value": 0.09878118948839716, "duration": 77.82452940940857, "info_performance_mean": 0.10140790790319443, "info_performance_final": 0.10508745163679123, "info_normalized_performance_mean": 0.22460216283798218, "info_normalized_performance_final": 0.24804265797138214, "step": 1300}
{"episode_reward": 507.0395741310387, "episode": 14.0, "batch_reward": 4.112702493667602, "critic_loss": 0.10221694428473711, "critic_lr": 0.00030000000000000073, "actor_loss": -10.861279430389404, "actor_target_entropy": -8.0, "actor_entropy": 10.319017391204834, "actor_lr": 0.0003, "alpha_loss": 1.3061741518974304, "alpha_value": 0.09828705370213461, "duration": 78.1566915512085, "info_performance_mean": 0.06614161282777786, "info_performance_final": 0.06614109128713608, "info_normalized_performance_mean": -6.147861131466925e-05, "info_normalized_performance_final": -6.486794154625386e-05, "step": 1400}
{"episode_reward": 330.7081164958276, "episode": 15.0, "batch_reward": 4.069855968952179, "critic_loss": 0.20459414657205344, "critic_lr": 0.00030000000000000073, "actor_loss": -12.636671886444091, "actor_target_entropy": -8.0, "actor_entropy": 10.287012157440186, "actor_lr": 0.0003, "alpha_loss": 1.301243441104889, "alpha_value": 0.09780023199315094, "duration": 78.03543210029602, "info_performance_mean": 0.0692143365740776, "info_performance_final": 0.07745391130447388, "info_normalized_performance_mean": 0.019513214007019997, "info_normalized_performance_final": 0.07200338691473007, "step": 1500}
{"episode_reward": 346.0716782110793, "episode": 16.0, "batch_reward": 4.0515167760849, "critic_loss": 0.23402521388605238, "critic_lr": 0.00030000000000000073, "actor_loss": -14.497508869171142, "actor_target_entropy": -8.0, "actor_entropy": 10.310538864135742, "actor_lr": 0.0003, "alpha_loss": 1.3026078581809997, "alpha_value": 0.09731441263136413, "duration": 77.9851713180542, "info_performance_mean": 0.07812506705522537, "info_performance_final": 0.07867156714200974, "info_normalized_performance_mean": 0.07627899199724197, "info_normalized_performance_final": 0.07976042479276657, "step": 1600}
{"episode_reward": 390.6253538497104, "episode": 17.0, "batch_reward": 4.030376119613647, "critic_loss": 0.41748186413198707, "critic_lr": 0.00030000000000000073, "actor_loss": -16.26052640914917, "actor_target_entropy": -8.0, "actor_entropy": 10.320795497894288, "actor_lr": 0.0003, "alpha_loss": 1.2965904355049134, "alpha_value": 0.09683154806613485, "duration": 78.36710667610168, "info_performance_mean": 0.07615730911493301, "info_performance_final": 0.06842616945505142, "info_normalized_performance_mean": 0.06374338269233704, "info_normalized_performance_final": 0.014492183923721313, "step": 1700}
{"episode_reward": 380.7865522118688, "episode": 18.0, "batch_reward": 4.046690247058868, "critic_loss": 0.19996886644512415, "critic_lr": 0.00030000000000000073, "actor_loss": -18.2425789642334, "actor_target_entropy": -8.0, "actor_entropy": 10.312907314300537, "actor_lr": 0.0003, "alpha_loss": 1.2839851427078246, "alpha_value": 0.09635365099134714, "duration": 78.14996433258057, "info_performance_mean": 0.07604114711284637, "info_performance_final": 0.08325828611850739, "info_normalized_performance_mean": 0.06300339102745056, "info_normalized_performance_final": 0.10898008942604065, "step": 1800}
{"episode_reward": 380.2057580559237, "episode": 19.0, "batch_reward": 4.0164867734909055, "critic_loss": 0.18528164956718685, "critic_lr": 0.00030000000000000073, "actor_loss": -20.072111206054686, "actor_target_entropy": -8.0, "actor_entropy": 10.313392543792725, "actor_lr": 0.0003, "alpha_loss": 1.276231050491333, "alpha_value": 0.09588143985209065, "duration": 78.23745012283325, "info_performance_mean": 0.08257672935724258, "info_performance_final": 0.08216880261898041, "info_normalized_performance_mean": 0.10463827103376389, "info_normalized_performance_final": 0.10203953087329865, "step": 1900}
{"episode_reward": 412.88367468287225, "episode": 20.0, "batch_reward": 4.00598801612854, "critic_loss": 0.3036987002566457, "critic_lr": 0.00030000000000000073, "actor_loss": -21.87452533721924, "actor_target_entropy": -8.0, "actor_entropy": 10.280761680603028, "actor_lr": 0.0003, "alpha_loss": 1.2670645332336425, "alpha_value": 0.09541278952277603, "duration": 77.70973062515259, "info_performance_mean": 0.07424315810203552, "info_performance_final": 0.07725868374109268, "info_normalized_performance_mean": 0.051549281924963, "info_normalized_performance_final": 0.07075965404510498, "step": 2000}
