{"step": 0}
{"episode_reward": 0.0, "episode": 1.0, "duration": 67.95291423797607, "info_performance_mean": 0.07326382398605347, "info_performance_final": 0.07177256047725677, "info_normalized_performance_mean": -0.02603246457874775, "info_normalized_performance_final": -0.03624247759580612, "step": 100}
{"episode_reward": 366.31913705186935, "episode": 2.0, "duration": 4.941923141479492, "info_performance_mean": 0.07735130190849304, "info_performance_final": 0.0775899589061737, "info_normalized_performance_mean": 0.0019526934484019876, "info_normalized_performance_final": 0.003586607286706567, "step": 200}
{"episode_reward": 386.7565439492932, "episode": 3.0, "duration": 5.156101703643799, "info_performance_mean": 0.0677264854311943, "info_performance_final": 0.06727373600006104, "info_normalized_performance_mean": -0.06394413858652115, "info_normalized_performance_final": -0.06704395264387131, "step": 300}
{"episode_reward": 338.6324463299966, "episode": 4.0, "duration": 5.032332420349121, "info_performance_mean": 0.08294809609651566, "info_performance_final": 0.08622298389673233, "info_normalized_performance_mean": 0.04027135297656059, "info_normalized_performance_final": 0.06269308924674988, "step": 400}
{"episode_reward": 414.74045324286857, "episode": 5.0, "duration": 4.937968015670776, "info_performance_mean": 0.08657357841730118, "info_performance_final": 0.09255068004131317, "info_normalized_performance_mean": 0.06509353965520859, "info_normalized_performance_final": 0.10601601004600525, "step": 500}
{"episode_reward": 432.8679568045775, "episode": 6.0, "duration": 5.008373260498047, "info_performance_mean": 0.08010202646255493, "info_performance_final": 0.08298640698194504, "info_normalized_performance_mean": 0.020785586908459663, "info_normalized_performance_final": 0.04053366556763649, "step": 600}
{"episode_reward": 400.5101016556137, "episode": 7.0, "duration": 4.964998960494995, "info_performance_mean": 0.07725532352924347, "info_performance_final": 0.0773104652762413, "info_normalized_performance_mean": 0.0012954919366165996, "info_normalized_performance_final": 0.0016730654751881957, "step": 700}
{"episode_reward": 386.27659303089035, "episode": 8.0, "duration": 4.949336528778076, "info_performance_mean": 0.08298594504594803, "info_performance_final": 0.09012234210968018, "info_normalized_performance_mean": 0.04053056612610817, "info_normalized_performance_final": 0.08939027041196823, "step": 800}
{"episode_reward": 414.92975407298593, "episode": 9.0, "duration": 5.046674489974976, "info_performance_mean": 0.08497016876935959, "info_performance_final": 0.08788412809371948, "info_normalized_performance_mean": 0.05411563813686371, "info_normalized_performance_final": 0.07406619191169739, "step": 900}
{"episode_reward": 424.8508607471625, "episode": 10.0, "duration": 4.96373724937439, "info_performance_mean": 0.07730412483215332, "info_performance_final": 0.07748118788003922, "info_normalized_performance_mean": 0.0016296181129291654, "info_normalized_performance_final": 0.0028419336304068565, "step": 1000}
{"episode_reward": 386.52060366649374, "episode": 11.0, "batch_reward": 3.934127848148346, "critic_loss": 0.8704911974072457, "critic_lr": 0.00030000000000000073, "actor_loss": -5.646115382313728, "actor_target_entropy": -8.0, "actor_entropy": 8.80548064470291, "actor_lr": 0.0003, "alpha_loss": 1.1327820220589637, "alpha_value": 0.09979933270984966, "duration": 13.647479772567749, "info_performance_mean": 0.06788001954555511, "info_performance_final": 0.06739389151334763, "info_normalized_performance_mean": -0.06289295852184296, "info_normalized_performance_final": -0.06622129678726196, "step": 1100}
{"episode_reward": 339.4001198730532, "episode": 12.0, "batch_reward": 3.896832237243652, "critic_loss": 0.16787876229733228, "critic_lr": 0.00030000000000000073, "actor_loss": -8.189065418243409, "actor_target_entropy": -8.0, "actor_entropy": 10.57502607345581, "actor_lr": 0.0003, "alpha_loss": 1.3285813307762147, "alpha_value": 0.0992684060890538, "duration": 13.424234867095947, "info_performance_mean": 0.07948563992977142, "info_performance_final": 0.08044007420539856, "info_normalized_performance_mean": 0.01656549796462059, "info_normalized_performance_final": 0.02310011349618435, "step": 1200}
{"episode_reward": 397.42819462547425, "episode": 13.0, "batch_reward": 3.9278195309638977, "critic_loss": 0.04382482759654522, "critic_lr": 0.00030000000000000073, "actor_loss": -10.010972290039062, "actor_target_entropy": -8.0, "actor_entropy": 10.549538345336915, "actor_lr": 0.0003, "alpha_loss": 1.324876501560211, "alpha_value": 0.09875715148394319, "duration": 13.482354402542114, "info_performance_mean": 0.0880487859249115, "info_performance_final": 0.09197127819061279, "info_normalized_performance_mean": 0.07519342750310898, "info_normalized_performance_final": 0.1020490750670433, "step": 1300}
{"episode_reward": 440.2438543258236, "episode": 14.0, "batch_reward": 3.941562466621399, "critic_loss": 0.03079437095671892, "critic_lr": 0.00030000000000000073, "actor_loss": -11.71973388671875, "actor_target_entropy": -8.0, "actor_entropy": 10.505597877502442, "actor_lr": 0.0003, "alpha_loss": 1.3184198021888733, "alpha_value": 0.09825649462394997, "duration": 13.489235877990723, "info_performance_mean": 0.07734611630439758, "info_performance_final": 0.07750355452299118, "info_normalized_performance_mean": 0.0019171186722815037, "info_normalized_performance_final": 0.002995066111907363, "step": 1400}
{"episode_reward": 386.7305637320498, "episode": 15.0, "batch_reward": 3.9367714023590086, "critic_loss": 0.04377029922790825, "critic_lr": 0.00030000000000000073, "actor_loss": -13.400784683227538, "actor_target_entropy": -8.0, "actor_entropy": 10.527565803527832, "actor_lr": 0.0003, "alpha_loss": 1.3116991376876832, "alpha_value": 0.09776249299421096, "duration": 13.710236072540283, "info_performance_mean": 0.07992971688508987, "info_performance_final": 0.08373448252677917, "info_normalized_performance_mean": 0.019605794921517372, "info_normalized_performance_final": 0.045655447989702225, "step": 1500}
